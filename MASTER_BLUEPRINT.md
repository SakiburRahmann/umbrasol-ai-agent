# Project Umbrasol: Master Blueprint
**Status:** Confidential / Internal / Agent-Handoff Ready
**Version:** 1.0.0 (January 2026)

## 0. Executive Summary
Project Umbrasol is an attempt to build a **Universal, 100% Local, Autonomous AI Agent** that performs real-world tasks on behalf of a user. Unlike "chatbots," Umbrasol is a "System Agent." It lives inside the user's operating system (Linux, Windows, Android) and interacts with the hardware and software directly through a "Dual-Soul" architecture. 

It is designed to be **Zero-Cost** (no APIs), **Zero-Latency** (local inference), and **Absolute Privacy** (no data leaves the device).

---

## 1. The Core Architecture: The "Dual-Soul" System
To solve the conflict between "High Autonomy" and "System Safety," Umbrasol uses two distinct LLM instances (souls) that verify each other in a loop.

### Brain 1: The Doer (Action Intelligence)
- **Role:** The Strategist.
- **Job:** Takes the user's natural language request and decomposes it into a sequence of executable code (Shell scripts, Python snippets, or ADB Intents).
- **Target Models (2026):** `GLM-4.7 Thinking` (High reasoning), `Llama 3.1 70B/8B`.
- **Primary Optimization:** High context window and "Thinking" mechanism (Chain of Thought).

### Brain 2: The Guardian (Security Intelligence)
- **Role:** The Policy Enforcer.
- **Job:** Intercepts every command generated by the Doer. It does NOT know the user's full context; it only analyzes the **safety** and **reversibility** of the command.
- **Target Models (2026)::** `Phi-3 Mini`, `SmolLM-135M`, `Llama 3.1 8B`.
- **Logic:** Must answer `[SAFE]` or `[DANGER]`. If `[DANGER]`, the Doer is blocked and forced to regenerate.

---

## 2. Dynamic Hardware Profiling & Tiered Strategy
Umbrasol includes a **Hardware Profiler** that runs at startup. It detects Total RAM, VRAM (NVIDIA/AMD), and NPU availability to automatically map the system to one of the following intelligence tiers.

### Tier 1: "Leviathan" - High-End PC / Workstation (32GB+ RAM / 16GB+ VRAM)
- **Doer:** `GLM-4.7 Thinking` (355B MoE / 32B Active).
- **Guardian:** `Llama 3.1 8B`.
- **Capability:** Full autonomous system refactoring, advanced research, complex logic.

### Tier 2: "Centurion" - Standard Laptop / Phone (8-16GB RAM)
- **Doer:** `Llama 3.1 8B` (Q4).
- **Guardian:** `Phi-3 Mini` (3.8B).
- **Capability:** Task automation, script writing, organizational work.

### Tier 3: "Ghost" - Budget / Ultra-Battery (Under 8GB RAM)
- **Doer:** `Liquid AI LFM 1.2B` or `Qwen 4B`.
- **Guardian:** `SmolLM 135M`.
- **Capability:** Background monitoring, simple file operations, notification handling.

### Optimization Protocols:
1.  **4-bit Quantization:** All models are compressed using GGUF/EXL2 formats to fit in VRAM/NPU memory.
2.  **NPU Direct-Access:** On mobile, we bypass the CPU/GPU and use the Neural Processing Unit for 10x battery efficiency.
3.  **Zero-Idle Activation:** The LLM is loaded into RAM but "frozen" (no CPU cycles) when not calculating a task.

---

## 3. Operational Modes: Ghost vs. UI
### Ghost Mode (Primary)
- **Method:** Headless execution via Terminal (CLI), ADB Intents, or background API calls.
- **Benefit:** Invisible to the user. Doesn't hijack the screen. Fast.
- **Action Layer:** Scripting (Bash/Python).

### Accessibility Mode (Secondary / Fallback)
- **Method:** Using Android Accessibility APIs or PC Mouse/Keyboard simulation.
- **Benefit:** Can control apps that have no API (e.g., a specific legacy app).
- **Control Layer:** Visual parsing (Screenshot-to-Coordinates).

---

## 4. Safety & The "Kill Switch"
- **The Blacklist:** Absolute block on commands targeting `/etc`, `/system`, `C:\Windows`, or `rm -rf /`.
- **The Reasoning Gate:** The Doer must provide a "Reasoning String." If the command doesn't match the reasoning, the Guardian kills the task.
- **3-Second Countdown:** For any "High Impact" task (deleting files, spending money), a user-facing notification appears with a "Cancel" button. If the user doesn't stop it, the agent proceeds after 3 seconds.

---

## 5. Technical Stack
- **Inference Engine:** `Ollama` (Linux/PC/Mac), `llama.cpp` (NPU/Mobile).
- **Application Engine:** `Flutter` (Dart) for Cross-Platform Desktop/Mobile UI.
- **Logic Core:** `Python` (Prototype), `Rust` (Production Shell Interface).
- **Mobile Control:** `Local ADB Bridge` (running on the device itself).

---

## 6. Implementation Roadmap
### Phase 1: The Desktop Core (Python Prototype)
- Build the "Thinking Loop" between the two brains.
- Implement the Shell Executor with the Blacklist.
- Status: **IN PROGRESS (Jan 2026)**.

### Phase 2: The Cross-Platform Soul (Flutter Integration)
- Port the Python logic to a Flutter App.
- Integrate `llama.cpp` for native NPU performance.
- Build the Android "Ghost Mode" via Intents.

### Phase 3: The Global Agent
- Implement encrypted local logs.
- Multi-Agent coordination (Phone talks to PC to sync tasks).
- Final packaging as .apk, .exe, .dmg.

---

## 7. Guidelines for the "Next Agent"
1.  **NEVER** suggest moving to the cloud. The project's "Soul" is its locality.
2.  **NEVER** bypass the Guardian brain.
3.  **ALWAYS** prioritize "Ghost Mode" (Terminal/Intent) over "UI Mode" (Clicking).
4.  **HARD REQUIREMENT:** All code must be runnable offline after the initial model pull.

---
*Signed,*
*The Initial Architect (Antigravity)*
